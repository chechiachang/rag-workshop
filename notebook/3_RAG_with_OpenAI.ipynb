{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9390e1e9-7be4-4744-84f8-c75ede9793bf",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-cookbook/blob/main/examples/vector_databases/qdrant/QA_with_Langchain_Qdrant_and_OpenAI.ipynb\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2025 OpenAI\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e56cffb-b15a-406d-931c-b1eadcfc5513",
   "metadata": {},
   "source": [
    "# 使用圖形資料庫進行檢索增強生成（RAG）\n",
    "\n",
    "本教學筆記展示如何將大型語言模型（LLM）與圖形資料庫 Qdrant 結合，來實現 Retrieval Augmented Generation（RAG）。\n",
    "\n",
    "---\n",
    "\n",
    "## 為什麼使用 RAG？\n",
    "\n",
    "如果你希望 LLM 根據你自己的內容或知識庫產生回答，而不是在 prompt 中塞入大量上下文，可以改為**從資料庫中擷取相關資訊**，並以此來生成回應。\n",
    "\n",
    "這樣做可以達到以下目的：\n",
    "\n",
    "* ✅ 減少模型幻覺（hallucination）\n",
    "* ✅ 為使用者提供即時且相關的資訊\n",
    "* ✅ 利用你自己的內容與知識庫\n",
    "\n",
    "---\n",
    "\n",
    "## 為什麼使用圖形資料庫？\n",
    "\n",
    "如果你的資料特別重視資料點之間的**關係**，或你希望能探索這些關聯性，那麼圖形資料庫會比傳統關聯式資料庫更合適。\n",
    "\n",
    "圖形資料庫特別擅長以下場景：\n",
    "\n",
    "* 🔍 深層層級結構的導航\n",
    "* 🧠 發現項目之間隱藏的連結\n",
    "* 🕸️ 探索資料點之間的關係\n",
    "\n",
    "---\n",
    "\n",
    "## 應用場景\n",
    "\n",
    "向量資料庫在以下應用中特別有價值：\n",
    "\n",
    "* 推薦系統\n",
    "* 社群網路關係分析\n",
    "* 客戶行為或資料點關聯分析\n",
    "\n",
    "使用向量資料庫進行 RAG 的實際應用範例包括：\n",
    "\n",
    "* 🛍️ 產品推薦聊天機器人\n",
    "* 🤖 AI 增強型 CRM 系統\n",
    "* 📊 使用自然語言分析使用者行為的工具\n",
    "\n",
    "---\n",
    "\n",
    "## 本筆記內容\n",
    "\n",
    "在本教學中，我們將建立一個 **COVID知識問答機器人**\n",
    "\n",
    "* 使用上一節準備好的 Qdrant Vector Database 與寫入的 COVID-QA collection 作為知識庫\n",
    "* 透過 OpenAI embedding model 將使用者輸入的問題產生文字嵌入，使用相同的 `text-embedding-3-large` model 產生的嵌入\n",
    "* 使用問題的 embedding 進入 Qdrant 做 query_point，找出最接近的 vector，以及對應的 COVID-QA 問答內容\n",
    "* 將問答內容提供給 LLM，讓 LLM 根據知識庫的問答內容，基於資訊回答問題\n",
    "\n",
    "👉 [https://www.kaggle.com/datasets/xhlulu/covidqa/data?select=community.csv](https://www.kaggle.com/datasets/xhlulu/covidqa/data?select=community.csv)\n",
    "\n",
    "---\n",
    "\n",
    "## 環境設定\n",
    "\n",
    "我們將從安裝與匯入必要的函式庫開始。\n",
    "\n",
    "請確保你已經擁有一個 [OpenAI 帳號](https://platform.openai.com/)，並準備好你的 OpenAI API 金鑰。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a5aa5-f670-4fae-82d3-923fb48fd4cc",
   "metadata": {},
   "source": [
    "## 📦 安裝所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f84052-b8b6-4bff-9df0-9bf2c8e3121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.12/site-packages (1.82.0)\n",
      "Requirement already satisfied: qdrant_client in /opt/conda/lib/python3.12/site-packages (1.14.2)\n",
      "Requirement already satisfied: tenacity in /opt/conda/lib/python3.12/site-packages (9.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /opt/conda/lib/python3.12/site-packages (from qdrant_client) (1.71.0)\n",
      "Requirement already satisfied: numpy>=1.26 in /opt/conda/lib/python3.12/site-packages (from qdrant_client) (2.2.6)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /opt/conda/lib/python3.12/site-packages (from qdrant_client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /opt/conda/lib/python3.12/site-packages (from qdrant_client) (5.29.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /opt/conda/lib/python3.12/site-packages (from qdrant_client) (2.4.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /opt/conda/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /opt/conda/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /opt/conda/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai qdrant_client tenacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eeb00a-1ad7-4d76-9781-78c373147390",
   "metadata": {},
   "source": [
    "### 🔐 設定 Azure OpenAI 的 API 金鑰與端點\n",
    "\n",
    "```python\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\"\" # 填上 api key\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\"\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2024-12-01-preview\" # 替換成你的 API 版本\n",
    "os.environ[\"OPENAI_MODEL\"]=\"text-embedding-3-large\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da50d0d7-2ece-459f-a319-64f15ae1dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\"\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2024-12-01-preview\"\n",
    "os.environ[\"OPENAI_MODEL\"]=\"gpt-4.1-mini\"\n",
    "\n",
    "if os.getenv(\"AZURE_OPENAI_API_KEY\") is not None:\n",
    "    print(\"AZURE_OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print(\"AZURE_OPENAI_API_KEY environment variable not found\")\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "openai_client = AzureOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b53cd-b505-4a7b-81d8-9146a092e4e4",
   "metadata": {},
   "source": [
    "### 建立 qdrant 連線並測試取得 collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa0b318-e55e-44ad-8706-64fb285c2916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='Articles')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"qdrant\",\n",
    "    prefer_grpc=True,\n",
    ")\n",
    "\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a1199-1732-431c-a79f-13377d0921e4",
   "metadata": {},
   "source": [
    "## 🔄 RAG 查詢流程說明\n",
    "\n",
    "1. **使用者輸入問題（自然語言）**\n",
    "   例如：「COVID 的全名是什麼？」\n",
    "\n",
    "2. **將問題轉成向量**\n",
    "   使用 OpenAI 的 `text-embedding-3-large` 或類似模型轉換問題為向量。\n",
    "\n",
    "3. **使用向量查詢 Qdrant**\n",
    "   Qdrant 使用近似最近鄰搜尋（ANN）找出相似的文檔或段落。\n",
    "\n",
    "4. **取得最相關的 context（上下文）**\n",
    "   根據 Qdrant 回傳的內容（例如 top-k 筆記錄），你可以拿到與問題相關的段落。\n",
    "\n",
    "5. **將 context 與原始問題組合成 prompt**\n",
    "   將 query + context 組合起來，如：\n",
    "\n",
    "   ```text\n",
    "   根據以下資料回答問題：\n",
    "   ===\n",
    "   [段落1]\n",
    "   [段落2]\n",
    "   ===\n",
    "   問題：COVID 的全名是什麼？\n",
    "   ```\n",
    "\n",
    "6. **送出給 GPT 模型進行生成回答**\n",
    "   傳送給 OpenAI 的 GPT-4 / GPT-3.5 模型生成最終回覆。\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 架構流程圖（文字版）\n",
    "\n",
    "```\n",
    "┌──────────────┐       ┌─────────────────────┐\n",
    "│ User Input   │       │ Embedding Model     │\n",
    "│ (e.g., Query)├──────▶│ (OpenAI Embeddings) │\n",
    "└──────────────┘       └────────────┬────────┘\n",
    "                                    │\n",
    "                                    ▼\n",
    "                            ┌───────────────┐\n",
    "                            │ Vector Query  │\n",
    "                            │ to Qdrant DB  │\n",
    "                            └──────┬────────┘\n",
    "                                   ▼\n",
    "                        ┌────────────────────┐\n",
    "                        │ Retrieved Contexts │\n",
    "                        └────────┬───────────┘\n",
    "                                 ▼\n",
    "                   ┌────────────────────────────┐\n",
    "                   │ Prompt Construction Module │\n",
    "                   │ (Query + Top-K Contexts)   │\n",
    "                   └────────┬───────────────────┘\n",
    "                            ▼\n",
    "                    ┌────────────────────┐\n",
    "                    │ OpenAI Chat Model  │\n",
    "                    │ (GPT-4.1 / GPT-4)  │\n",
    "                    └────────┬───────────┘\n",
    "                             ▼\n",
    "                    ┌────────────────────┐\n",
    "                    │ Final Answer       │\n",
    "                    └────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6856e0-8abe-428b-aa84-8ee4a22cbc87",
   "metadata": {},
   "source": [
    "## 🔄 RAG 查詢流程說明\n",
    "\n",
    "1. **使用者輸入問題（自然語言）**\n",
    "   例如：「COVID 的全名是什麼？」\n",
    "\n",
    "2. **將問題轉成向量**\n",
    "   使用 OpenAI 的 `text-embedding-3-large` 或類似模型轉換問題為向量。\n",
    "\n",
    "3. **使用向量查詢 Qdrant**\n",
    "   Qdrant 使用近似最近鄰搜尋（ANN）找出相似的文檔或段落。\n",
    "\n",
    "4. **取得最相關的 context（上下文）**\n",
    "   根據 Qdrant 回傳的內容（例如 top-k 筆記錄），你可以拿到與問題相關的段落。\n",
    "\n",
    "5. **將 context 與原始問題組合成 prompt**\n",
    "   將 query + context 組合起來，如：\n",
    "\n",
    "   ```text\n",
    "   根據以下資料回答問題：\n",
    "   ===\n",
    "   [段落1]\n",
    "   [段落2]\n",
    "   ===\n",
    "   問題：COVID 的全名是什麼？\n",
    "   ```\n",
    "\n",
    "6. **送出給 GPT 模型進行生成回答**\n",
    "   傳送給 OpenAI 的 GPT-4 / GPT-3.5 模型生成最終回覆。\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 架構流程圖（文字版）\n",
    "\n",
    "```\n",
    "┌──────────────┐       ┌─────────────────────┐\n",
    "│ User Input   │       │ Embedding Model     │\n",
    "│ (e.g., Query)├──────▶│ (OpenAI Embeddings) │\n",
    "└──────────────┘       └────────────┬────────┘\n",
    "                                    │\n",
    "                                    ▼\n",
    "                            ┌───────────────┐\n",
    "                            │ Vector Query  │\n",
    "                            │ to Qdrant DB  │\n",
    "                            └──────┬────────┘\n",
    "                                   ▼\n",
    "                        ┌────────────────────┐\n",
    "                        │ Retrieved Contexts │\n",
    "                        └────────┬───────────┘\n",
    "                                 ▼\n",
    "                   ┌────────────────────────────┐\n",
    "                   │ Prompt Construction Module │\n",
    "                   │ (Query + Top-K Contexts)   │\n",
    "                   └────────┬───────────────────┘\n",
    "                            ▼\n",
    "                    ┌────────────────────┐\n",
    "                    │ OpenAI Chat Model  │\n",
    "                    │ (GPT-4.1 / GPT-4)  │\n",
    "                    └────────┬───────────┘\n",
    "                             ▼\n",
    "                    ┌────────────────────┐\n",
    "                    │ Final Answer       │\n",
    "                    └────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc0b708-771d-4295-a374-70dc371a3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),  # backoff 等待時間\n",
    "    stop=stop_after_attempt(6),  # 最多重試 6 次\n",
    ")\n",
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    res = openai_client.embeddings.create(\n",
    "        model=model,\n",
    "        input=[text]\n",
    "    )\n",
    "    return res.data[0].embedding\n",
    "\n",
    "def query_docs(query, collection_name=\"covid-qa-3-large\", model=\"text-embedding-3-large\" , top_k=5):\n",
    "    query_vect = get_embedding(query, model)\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vect,\n",
    "        limit=5,\n",
    "        with_payload=True,\n",
    "        using=\"title\"\n",
    "    )\n",
    "    payloads = [point.payload[\"answer\"] for point in results.points]\n",
    "    return payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3463fa1-7aae-4608-b4da-9c6462ff19e4",
   "metadata": {},
   "source": [
    "5. **將 context 與原始問題組合成 prompt**\n",
    "   將 query + context 組合起來，如：\n",
    "\n",
    "   ```text\n",
    "   根據以下資料回答問題：\n",
    "   ===\n",
    "   [段落1]\n",
    "   [段落2]\n",
    "   ===\n",
    "   問題：COVID 的全名是什麼？\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef13992-8151-41cb-89cf-79fcdd1bb5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),  # backoff 等待時間\n",
    "    stop=stop_after_attempt(6),  # 最多重試 6 次\n",
    ")\n",
    "def generate_answer(query, docs, model=\"gpt-4.1-mini\"):\n",
    "    context = \"\\n\\n\".join(docs)\n",
    "    prompt = f\"\"\"根據以下內容回答問題：\n",
    "\n",
    "1. 請用繁體中文回答\n",
    "2. 依照內容產生回答\n",
    "3. 附上內容原文作為依據，原文保留內容的原始語言\n",
    "4. 如果內容不包含就回答我不知道\n",
    "\n",
    "內容：\n",
    "{context}\n",
    "\n",
    "問題：\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=model,  # 或你的 Azure 模型名稱\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一個 helpful AI 助理\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1827b99-c2cc-41e3-bb63-6b144fd639ef",
   "metadata": {},
   "source": [
    "### 🔄 RAG 查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1854bb6b-b936-4363-a21c-495af8f0838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 回答：\n",
      "COVID 的全名是「Coronavirus Disease 2019」，簡稱 COVID-19。\n",
      "\n",
      "依據原文：\n",
      "\"WHO announced “COVID-19” as the name of this new disease on 11 February 2020, following guidelines previously developed with the World Organisation for Animal Health (OIE) and the Food and Agriculture Organization of the United Nations (FAO).\"\n"
     ]
    }
   ],
   "source": [
    "query = \"COVID 的全名是什麼\"\n",
    "docs = query_docs(\n",
    "    query=query,\n",
    "    collection_name=\"covid-qa-3-large\",\n",
    "    model=\"text-embedding-3-large\")\n",
    "\n",
    "answer = generate_answer(\n",
    "    query=query, \n",
    "    docs=docs, \n",
    "    model=\"gpt-4.1-mini\")\n",
    "\n",
    "print(\"\\n🧠 回答：\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05239a02-169c-460f-8137-641dd76bf1e2",
   "metadata": {},
   "source": [
    "### 🔄 RAG 查詢問題2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf9c3e3-5630-4961-bc79-34d7d868d7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 回答：\n",
      "根據提供的內容，關於新冠病毒（SARS-CoV-2）的潛伏期資訊如下：\n",
      "\n",
      "- 在一段引用中提到：「Because fourteen days have elapsed since their departure from Wuhan—longer than the 95th percentile estimate of the COVID-19 incubation period (Li et al., 2020; Linton et al., 2020)」，意即14天已超過新冠病毒潛伏期的95百分位數估計值。\n",
      "\n",
      "因此，新冠病毒的潛伏期大約是14天以內，這也是目前普遍接受的隔離觀察天數。\n",
      "\n",
      "---\n",
      "\n",
      "內容原文依據：\n",
      "\n",
      "> \"Because fourteen days have elapsed since their departure from Wuhan—longer than the 95th percentile estimate of the COVID-19 incubation period (Li et al., 2020; Linton et al., 2020)—there is very little probability that the five virus-positive asymptomatic individuals will develop symptoms.\"\n",
      "\n",
      "---\n",
      "\n",
      "結論：新冠病毒的潛伏期約為14天以內。\n"
     ]
    }
   ],
   "source": [
    "query = \"新冠病毒潛伏期多久？\"\n",
    "docs = query_docs(\n",
    "    query=query,\n",
    "    collection_name=\"covid-qa-3-large\",\n",
    "    model=\"text-embedding-3-large\")\n",
    "\n",
    "answer = generate_answer(\n",
    "    query=query, \n",
    "    docs=docs, \n",
    "    model=\"gpt-4.1-mini\")\n",
    "\n",
    "print(\"\\n🧠 回答：\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a8680-bbdf-45f9-8849-b1b238622472",
   "metadata": {},
   "source": [
    "### 🔄 檢查 RAG 取得的 context\n",
    "\n",
    "* 檢查 context 內容\n",
    "* Qdrant 有撈出對應的資料作為 context\n",
    "* LLM 確實有使用 context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dca0438-8f66-4f42-8a9c-2130034070cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 查詢結果：\n",
      "- An early release paper dated 23 March 2020 is now staying that SARS-CoV-2 RNA has been recovered 17 days after both infected and asymptomatic presumed infected passengers left the cabins of the Diamond Pricess cruise ship.\n",
      "\n",
      "The discovery of virus on surfaces of asymptomatic passengers again demonstrates that viral shedding occurs in this phase in amounts sufficient to contaminate the environment.\n",
      "\n",
      "\n",
      "  SARS-CoV-2 RNA was identified on a variety of surfaces in cabins of both symptomatic and asymptomatic infected passengers up to 17 days after cabins were vacated on the Diamond Princess but before disinfection procedures had been conducted (Takuya Yamagishi, National Institute of Infectious Diseases, personal communication, 2020). Although these data cannot be used to determine whether transmission occurred from contaminated surfaces, further study of fomite transmission of SARS-CoV-2 aboard cruise ships is warranted.\n",
      "\n",
      "\n",
      "https://www.cdc.gov/mmwr/volumes/69/wr/mm6912e3.htm \n",
      "Public Health Responses to COVID-19 Outbreaks on Cruise Ships — Worldwide, February–March 2020 \n",
      "Early Release / March 23, 2020 / 69\n",
      " ...\n",
      "- You are searching for the false-negative rate of these tests. A test resulting in a negative outcome while it should have been a positive outcome. \n",
      "\n",
      "A recent article stated that most of the false-negatives of COVID-19 tests are actually caused by not properly taking the samples from nose and throat. While I cannot find the original article I've got this information from, I've added two other relevant quotes. So yes false-negatives are possible but are likely caused by samples that are not properly collected.\n",
      "\n",
      "\n",
      "  The rollout of COVID-19 testing is accelerating as more kits become available. However, a leading pathologist who was director of virology at Stanford, points out that the results are not 100% accurate. \"It's not that these tests can't detect virus,\" said Dr. Bruce Patterson. \"My concern is that the sampling involved in detecting the virus can lead to clinical false negatives.\" - https://abc7news.com/6053940/\n",
      "\n",
      "\n",
      "Also, the false-negative rate can vary based on the test method used and its quality and accuracy.\n",
      "\n",
      "\n",
      "  COVID-19 tests are new, and assessing their accuracy is challenging. PCR tests may produce false negatives, failing to identify evidence of SARS-CoV-2. Sometimes false negatives result from human error or problems with the procedure. Giving the test too early or late, for example, can lead to a false negative. - https://www.medicalnewstoday.com/articles/coronavirus-testing#accuracy\n",
      "\n",
      " ...\n",
      "- Since it seems unlikely that these data are available already from the novel virus, I'll refer to other coronavirus strains associated with outbreaks, the SARS-CoV coronavirus associated with an outbreak in 2003 and MERS-CoV.\n",
      "\n",
      "In reference to the stability of the virus outside the body for SARS-CoV, the WHO consensus document said:\n",
      "\n",
      "\n",
      "  Data from the Chinese University in Hong Kong indicated that SARS-CoV has\n",
      "  been isolated from stool on paper, a Formica surface and a plastered wall after 36 hours, on a plastic surface and stainless steel after 72 hours, and after 96 hours on a glass slide.\n",
      "  Hospital environmental samples from a number of sites, including walls and the ventilation\n",
      "  system, tested PCR positive in Canada.\n",
      "\n",
      "\n",
      "A later follow-up confirmed that SARS-CoV is viable possibly for days in the right conditions:\n",
      "\n",
      "\n",
      "  In the present study, we have demonstrated that SARS CoV can survive at least two weeks after drying at temperature and humidity conditions found in an air-conditioned environment. The virus is stable for 3 weeks at room temperature in a liquid environment1\n",
      "\n",
      "\n",
      "1Chan, K. H., Peiris, J. S., Lam, S. Y., Poon, L. L. M., Yuen, K. Y., &amp; Seto, W. H. (2011). The effects of temperature and relative humidity on the viability of the SARS coronavirus. Advances in virology, 2011.\n",
      "\n",
      "This suggests that SARS-CoV was better at surviving in the environment than other related strains, especially in cool temperatures. However, there was still a substantial decrease in viral titre by 1 week.\n",
      "\n",
      "For MERS-CoV,\n",
      "\n",
      "\n",
      "  MERS-CoV virus could still be recovered after 48 hours2\n",
      "\n",
      "\n",
      "...on plastic and steel surfaces, though not at 72 hours, at 20C. The virus degraded more quickly at higher temperatures.\n",
      "\n",
      "2Van Doremalen, N., Bushmaker, T., &amp; Munster, V. J. (2013). Stability of Middle East respiratory syndrome coronavirus (MERS-CoV) under different environmental conditions. Eurosurveillance, 18(38), 20590.\n",
      "\n",
      "\n",
      "\n",
      "Assuming the new 2019-nCoV virus is similar to these, there is a risk of environmental transmission particularly in high-exposure locations like hospitals. It seems far less likely to be a risk after multiple weeks, but there is still little known about the new strain.\n",
      "\n",
      "I was unable to find more than speculation about rates of actual infection due to exposure in these conditions, but that speculation is mostly focused on the health care setting and in particular on transmission in health care settings despite extensive precautions.\n",
      "\n",
      "It's very difficult to connect culture viability to actual transmission risks, and not really ethical to swipe different concentrations of a coronavirus on the surfaces of a room and let people wander through to see how many get sick. Therefore, the best evidence for surface transmission of these viruses is when other methods of exposure can be mostly ruled out, and this is a very imperfect estimate.\n",
      " ...\n",
      "- \n",
      "  The proportion of individuals infected by SARS-CoV-2 who remain\n",
      "  asymptomatic throughout the course of infection has not\n",
      "  yet been definitely assessed.\n",
      "\n",
      "\n",
      "\n",
      "The COVID-19 epidemic, Tropical Medicine &amp; International health (2020)\n",
      "\n",
      "\n",
      "\n",
      "  The asymptomatic ratio is thus estimated at 41.6% (95% confidence interval (CI): 16.7%, 66.7%) among evacuees. Because fourteen days have elapsed since their departure from Wuhan—longer than the 95th percentile estimate of the COVID-19 incubation period (Li et al., 2020; Linton et al., 2020)—there is very little probability that the five virus-positive asymptomatic individuals will develop symptoms. Should one of the five becomes symptomatic in the future, the overall asymptomatic ratio would decrease to 33.3% (95% CI: 8.3%, 58.3%). \n",
      "\n",
      "\n",
      "\n",
      "Estimation of the asymptomatic ratio of novel coronavirus infections (COVID-19), International Journal of Infectious Diseases (2020)\n",
      "\n",
      "\n",
      "\n",
      "  Our estimated asymptomatic proportion is at 17.9% (95%CrI: 15.5–20.2%), which overlaps with a recently derived estimate of 33.3% (95% confidence interval: 8.3–58.3%) from data of Japanese citizens evacuated from Wuhan [13].\n",
      "\n",
      "\n",
      "\n",
      "Estimating the asymptomatic proportion of coronavirus disease 2019 (COVID-19) cases on board the Diamond Princess cruise ship, Yokohama, Japan, 2020, Eurosurveillance (2020)\n",
      "\n",
      "\n",
      "\n",
      "  Table S1. Model parameters. All time periods are given in days.\n",
      "\n",
      "Parameter                     Baseline              Distribution  Reference/reason\n",
      "                              (alternative values)  \n",
      "...\n",
      "Pr(Asymptomatic | Infection)  0.178 (0.1, 0.5)      Beta          Mizumoto et al. (13) (lower, higher)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimating unobserved SARS-CoV-2 infections in the United States (preprint) (2020)\n",
      "\n",
      " ...\n",
      "- Yes, it is possible to have no symptoms and be infected, various sources, e. g. https://www.ncbi.nlm.nih.gov/pubmed/32179137.\n",
      "\n",
      "As for testing after 'clearing the infection', this would be what a serological scarring test would look for, e. g.: \n",
      "\n",
      "\n",
      "https://www.statnews.com/2020/03/27/serological-tests-reveal-immune-coronavirus/\n",
      "https://www.contagionlive.com/news/florian-krammer-phd-discusses-new-coronavirus-serological-assay.\n",
      "\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 查詢結果：\")\n",
    "for d in docs:\n",
    "    print(\"-\", d, \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058cfa30-f68f-4fbc-bfb1-bbf64f706148",
   "metadata": {},
   "source": [
    "---\n",
    "# 小結: Embedding\n",
    "\n",
    "1. 使用 Qdrant Vector Database 與寫入的 COVID-QA collection 作為知識庫\n",
    "1. 透過 OpenAI embedding model 將使用者輸入的問題產生文字嵌入，使用相同的 model 產生嵌入\n",
    "1. 使用問題的嵌入進入 Qdrant 做 query_point，找出最接近的 vector，以及對應的 COVID-QA 問答內容\n",
    "1. 將問答內容提供給 LLM，讓 LLM 根據知識庫的問答內容回答問題\n",
    "\n",
    "---\n",
    "\n",
    "# 👋👋👋自己動手做看看👋👋👋\n",
    "\n",
    "嘗試使用不同的資料集 `community_embedded_text_embedding_3_small.csv` 進行 Embedding Search\n",
    "\n",
    "### 目標：讓 query_results 使用另外一個資料集\n",
    "\n",
    "1. client.get_collections() 會出現多個 collection\n",
    "2. query_results \n",
    "\n",
    "---\n",
    "\n",
    "### 提示\n",
    "\n",
    "1. 需要使用 [2_Embedding_Search_with_Qdrant_and_OpenAI](2_Embedding_Search_with_Qdrant_and_OpenAI.ipynb) 建立的新的 collection，如果沒有可以先回到 2\n",
    "2. 嘗試使用不同的 model （ex. model=\"gpt-4.1\")，結果會有所不同嗎？\n",
    "3. 如果 collection 與 model 使用不同的 embedding model，結果跑得出來嗎？`collection_name=\"covid-qa-3-large\" model=\"text-embedding-3-large\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db5557-3aae-4065-b132-eeb21ec1e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"想一個新的問題\"\n",
    "docs = query_docs(\n",
    "    query=query,\n",
    "    collection_name=\"\",\n",
    "    model=\"\")\n",
    "\n",
    "answer = generate_answer(\n",
    "    query=query, \n",
    "    docs=docs, \n",
    "    model=\"\")\n",
    "\n",
    "print(\"\\n🧠 回答：\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3239da-5798-4180-a4c7-cf90a6820db9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 👋👋👋自己動手做看看👋👋👋\n",
    "\n",
    "嘗試修改不同的 prompt，可以增加更多條件\n",
    "\n",
    "```\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),  # backoff 等待時間\n",
    "    stop=stop_after_attempt(6),  # 最多重試 6 次\n",
    ")\n",
    "def generate_answer(query, docs, model=\"gpt-4.1-mini\"):\n",
    "    context = \"\\n\\n\".join(docs)\n",
    "    prompt = f\"\"\"根據以下內容回答問題：\n",
    "\n",
    "1. 請用繁體中文回答\n",
    "2. 依照內容產生回答\n",
    "3. 附上內容原文作為依據，原文保留內容的原始語言\n",
    "4. 如果內容不包含就回答我不知道\n",
    "\n",
    "內容：\n",
    "{context}\n",
    "\n",
    "問題：\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=model,  # 或你的 Azure 模型名稱\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一個 helpful AI 助理\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d995f05-caf0-4788-83d6-3d10a7bf540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=60),  # backoff 等待時間\n",
    "    stop=stop_after_attempt(6),  # 最多重試 6 次\n",
    ")\n",
    "def generate_better_answer(query, docs, model=\"gpt-4.1-mini\"):\n",
    "    context = \"\\n\\n\".join(docs)\n",
    "    prompt = f\"\"\"\n",
    "    \n",
    "這邊都可以改，發揮創意\n",
    "\n",
    "內容：\n",
    "{context}\n",
    "\n",
    "問題：\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    res = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一個 helpful AI 助理\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return res.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cebd44-1e20-4080-93cd-071814b15503",
   "metadata": {},
   "source": [
    "#### 使用相同問題，看使用不同的 prompt，LLM 的回答有和不同 \n",
    "\n",
    "1. 可以使用 chatGPT 產生 prompt，再把 prompt 丟進來程式碼中\n",
    "2. 回答有什麼差異\n",
    "3. 你修改的 prompt 效果，比原先講師提供的 prompt，哪個更好？\n",
    "4. 呈上，基於什麼標準讓你覺得哪段 prompt 的效果比較好？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ccaa8-f4c7-4c8f-ae78-4cfce0099d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = query_docs(\n",
    "    query=query,\n",
    "    collection_name=\"\",\n",
    "    model=\"\")\n",
    "\n",
    "answer = generate_answer(\n",
    "    query=query, \n",
    "    docs=docs, \n",
    "    model=\"\")\n",
    "\n",
    "print(\"\\n🧠 回答：\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b985ea5-a222-40dd-88cc-0c0db2f68ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931f791-c9ee-4e38-b240-5e84e0f60419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
